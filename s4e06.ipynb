{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 1"
      ],
      "metadata": {
        "id": "SFz-9ZwILbl0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NoRiqXz05JKd"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "import numpy as np\n",
        "import os\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import missingno as msno\n",
        "from prettytable import PrettyTable\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "sns.set(style='darkgrid', font_scale=1.4)\n",
        "from tqdm import tqdm\n",
        "from tqdm.notebook import tqdm as tqdm_notebook\n",
        "tqdm_notebook.get_lock().locks = []\n",
        "# !pip install sweetviz\n",
        "# import sweetviz as sv\n",
        "import concurrent.futures\n",
        "from copy import deepcopy\n",
        "from functools import partial\n",
        "from itertools import combinations\n",
        "import random\n",
        "from random import randint, uniform\n",
        "import gc\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler,PowerTransformer, FunctionTransformer\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from itertools import combinations\n",
        "from sklearn.impute import SimpleImputer\n",
        "import xgboost as xg\n",
        "from sklearn.model_selection import train_test_split,cross_val_score\n",
        "from sklearn.metrics import mean_squared_error,mean_squared_log_error, roc_auc_score, accuracy_score, f1_score, precision_recall_curve, log_loss\n",
        "from sklearn.cluster import KMeans\n",
        "!pip install yellowbrick\n",
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "!pip install gap-stat\n",
        "from gap_statistic.optimalK import OptimalK\n",
        "from scipy import stats\n",
        "import statsmodels.api as sm\n",
        "from scipy.stats import ttest_ind\n",
        "from scipy.stats import boxcox\n",
        "import math\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "!pip install optuna\n",
        "import optuna\n",
        "!pip install cmaes\n",
        "import cmaes\n",
        "import xgboost as xgb\n",
        "!pip install catboost\n",
        "!pip install lightgbm --install-option=--gpu --install-option=\"--boost-root=C:/local/boost_1_69_0\" --install-option=\"--boost-librarydir=C:/local/boost_1_69_0/lib64-msvc-14.1\"\n",
        "import lightgbm as lgb\n",
        "!pip install category_encoders\n",
        "from category_encoders import OneHotEncoder, OrdinalEncoder, CountEncoder, CatBoostEncoder\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier, GradientBoostingClassifier,ExtraTreesClassifier, AdaBoostClassifier, HistGradientBoostingRegressor\n",
        "!pip install -U imbalanced-learn\n",
        "from imblearn.ensemble import BalancedRandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from catboost import CatBoost, CatBoostRegressor, CatBoostClassifier\n",
        "from sklearn.svm import NuSVC, SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifierCV, LogisticRegressionCV\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from catboost import Pool\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "pd.pandas.set_option('display.max_columns',None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "table = PrettyTable()\n",
        "\n",
        "table.field_names = ['Feature', 'Data Type', 'Train Missing %', 'Test Missing %',\"Original Missing%\"]\n",
        "for column in train_copy.columns:\n",
        "    data_type = str(train_copy[column].dtype)\n",
        "    non_null_count_train= np.round(100-train_copy[column].count()/train_copy.shape[0]*100,1)\n",
        "    if column!=target:\n",
        "        non_null_count_test = np.round(100-test_copy[column].count()/test_copy.shape[0]*100,1)\n",
        "    else:\n",
        "        non_null_count_test=\"NA\"\n",
        "    non_null_count_orig= np.round(100-original_copy[column].count()/original_copy.shape[0]*100,1)\n",
        "    table.add_row([column, data_type, non_null_count_train,non_null_count_test,non_null_count_orig])\n",
        "print(table)"
      ],
      "metadata": {
        "id": "8aIQMMcDLmen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_pie_chart(data, title, ax):\n",
        "    data_counts = data[target].value_counts()\n",
        "    labels = data_counts.index\n",
        "    sizes = data_counts.values\n",
        "    colors = [ (0.2, 0.9, 0.6), 'crimson', (0.8, 0.5, 0.3)]\n",
        "    explode = (0.1,0.05, 0)\n",
        "\n",
        "    ax.pie(sizes,explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=140)\n",
        "    ax.axis('equal')\n",
        "    ax.set_title(title)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(18, 6))  # Create three subplots in a row\n",
        "\n",
        "plot_pie_chart(train_copy, \"Train Churn Distribution\", axes[0])\n",
        "plot_pie_chart(original, \"Original Churn Distribution\", axes[1])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UYwEYXy-dLRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_cols = [f for f in train.columns if (train[f].dtype != 'O' and train[f].nunique() <100) or (train[f].dtype == 'O' and f not in [target]) ]\n",
        "custom_palette = (0.2, 0.9, 0.6), 'crimson', (0.8, 0.5, 0.3)\n",
        "for col in cat_cols:\n",
        "    contingency_table = pd.crosstab(train[col], train[target], normalize='index')\n",
        "    sns.set(style=\"whitegrid\")\n",
        "    contingency_table.plot(kind=\"bar\", stacked=True, color=custom_palette,figsize=(20, 4))\n",
        "    plt.title(f\"Percentage Distribution of Target across {col}\")\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel(\"Percentage\")\n",
        "    plt.legend(title=\"Target Class\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "A6c0cg79dSDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_map={\n",
        "'Graduate':0,\n",
        "'Enrolled':1,\n",
        "'Dropout':2}\n",
        "lgb_params = {\n",
        "    'n_estimators': 50,\n",
        "    'max_depth': 8,\n",
        "    'learning_rate': 0.02,\n",
        "    'subsample': 0.20,\n",
        "    'colsample_bytree': 0.56,\n",
        "    'reg_alpha': 0.25,\n",
        "    'reg_lambda': 5e-08,\n",
        "    'objective': 'multiclass',\n",
        "    'metric': 'multi_logloss',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'random_state': 42,\n",
        "    'device':device.lower(),\n",
        "    'verbose':-1\n",
        "    }\n",
        "\n",
        "def encode(y,target_map):\n",
        "    '''\n",
        "    To convert the outputs to numbers\n",
        "    '''\n",
        "    y=np.array(y)\n",
        "    encoded_y=[target_map[f] for f in y]\n",
        "    return encoded_y\n",
        "def decode(y,target_map):\n",
        "    '''To convert the predictions back to classes\n",
        "    '''\n",
        "    y=np.array(y)\n",
        "    reverse_dict={v: k for k, v in target_map.items()}\n",
        "    decoded_y=[reverse_dict[f] for f in y]\n",
        "    return decoded_y\n",
        "def min_max_scaler(train, test, column):\n",
        "    '''\n",
        "    Min Max just based on train might have an issue if test has extreme values, hence changing the denominator using overall min and max\n",
        "    '''\n",
        "    max_val=max(train[column].max(),test[column].max())\n",
        "    min_val=min(train[column].min(),test[column].min())\n",
        "\n",
        "    train[column]=(train[column]-min_val)/(max_val-min_val)\n",
        "    test[column]=(test[column]-min_val)/(max_val-min_val)\n",
        "\n",
        "    return train,test\n",
        "\n",
        "hgbm_params={'learning_rate': 0.07590136944725749, 'max_depth': 6, 'min_samples_leaf': 12, 'max_leaf_nodes': 5}\n",
        "lgb_params1 = {\n",
        "            'n_estimators': 50,\n",
        "            'max_depth': 6,\n",
        "            \"num_leaves\": 16,\n",
        "            'learning_rate': 0.002,\n",
        "            'subsample': 0.7,\n",
        "            'colsample_bytree': 0.8,\n",
        "            #'reg_alpha': 0.25,\n",
        "#             'reg_lambda': 5e-07,\n",
        "            \"boosting_type\": \"gbdt\",\n",
        "            \"objective\":'regression_l1',\n",
        "            'metric': 'mean_absolute_error',\n",
        "            'device': device.lower(),\n",
        "            'random_state': 42,\n",
        "            'verbose':-1\n",
        "        }\n",
        "def store_missing_rows(df, features):\n",
        "    '''Function stores where missing values are located for given set of features'''\n",
        "    missing_rows = {}\n",
        "\n",
        "    for feature in features:\n",
        "        missing_rows[feature] = df[df[feature].isnull()]\n",
        "\n",
        "    return missing_rows\n",
        "def fill_missing_numerical(train,test,target, max_iterations=10):\n",
        "    '''Iterative Missing Imputer: Updates filled missing values iteratively using CatBoost Algorithm'''\n",
        "    train_temp=train.copy()\n",
        "    if target in train_temp.columns:\n",
        "        train_temp=train_temp.drop(columns=target)\n",
        "\n",
        "\n",
        "    df=pd.concat([train_temp,test],axis=\"rows\")\n",
        "    df=df.reset_index(drop=True)\n",
        "    features=[ f for f in df.columns if df[f].isna().sum()>0]\n",
        "    if len(features)>0:\n",
        "        # Step 1: Store the instances with missing values in each feature\n",
        "        missing_rows = store_missing_rows(df, features)\n",
        "\n",
        "        # Step 2: Initially fill all missing values with \"Missing\"\n",
        "        for f in features:\n",
        "            df[f]=df[f].fillna(df[f].median())\n",
        "\n",
        "        cat_features=[f for f in df.columns if not pd.api.types.is_numeric_dtype(df[f])]\n",
        "        dictionary = {feature: [] for feature in features}\n",
        "\n",
        "        for iteration in tqdm(range(max_iterations), desc=\"Iterations\"):\n",
        "            for feature in features:\n",
        "#                 print(feature)\n",
        "                # Skip features with no missing values\n",
        "                rows_miss = missing_rows[feature].index\n",
        "                replace_dict={}\n",
        "                rev_replace_dict={}\n",
        "                for col in  cat_features:\n",
        "                    df[col]=df[col].astype(str)\n",
        "                    int_cat=dict(zip(df[col].unique(),np.arange(0, df[col].nunique())))\n",
        "                    rev_int_cat=dict(zip(np.arange(0, df[col].nunique()), df[col].unique()))\n",
        "                    df[col]=df[col].replace(int_cat)\n",
        "\n",
        "                    replace_dict[col]=int_cat\n",
        "                    rev_replace_dict[col]=rev_int_cat\n",
        "\n",
        "                missing_temp = df.loc[rows_miss].copy()\n",
        "                non_missing_temp = df.drop(index=rows_miss).copy()\n",
        "                y_pred_prev=missing_temp[feature]\n",
        "                missing_temp = missing_temp.drop(columns=[feature])\n",
        "\n",
        "\n",
        "                # Step 3: Use the remaining features to predict missing values using Random Forests\n",
        "                X_train = non_missing_temp.drop(columns=[feature])\n",
        "                y_train = non_missing_temp[[feature]]\n",
        "\n",
        "                model1 =HistGradientBoostingRegressor(**hgbm_params, max_iter=100, loss=\"absolute_error\", n_iter_no_change=50,random_state=42)\n",
        "                model1.fit(X_train, y_train)\n",
        "\n",
        "                model2 = lgb.LGBMRegressor(**lgb_params1)\n",
        "                model2.fit(X_train, y_train)\n",
        "\n",
        "                # Step 4: Predict missing values for the feature and update all N features\n",
        "                y_pred = (np.array(model1.predict(missing_temp))+np.array(model2.predict(missing_temp)))/2\n",
        "                df.loc[rows_miss, feature] = y_pred\n",
        "#                 error_minimize=rmse(y_pred,y_pred_prev) #mean_squared_error\n",
        "                error_minimize=mean_squared_error(y_pred,y_pred_prev) #mean_squared_error\n",
        "                dictionary[feature].append(error_minimize)  # Append the error_minimize value\n",
        "\n",
        "                for col in  cat_features:\n",
        "                    df[col]=df[col].replace(rev_int_cat)\n",
        "\n",
        "\n",
        "        for feature, values in dictionary.items():\n",
        "            values=np.array(values)/sum(values)\n",
        "            iterations = range(1, len(values) + 1)  # x-axis values (iterations)\n",
        "            plt.plot(iterations, values, label=feature)  # plot the values\n",
        "            plt.xlabel('Iterations')\n",
        "            plt.ylabel('RMSE')\n",
        "            plt.title('Minimization of RMSE with iterations')\n",
        "            plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "        plt.show()\n",
        "        train[features] = np.array(df.iloc[:train.shape[0]][features])\n",
        "        test[features] = np.array(df.iloc[train.shape[0]:][features])\n",
        "\n",
        "    return train,test"
      ],
      "metadata": {
        "id": "L3r8G2U0oGjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_cols = [f for f in test.columns if (train[f].dtype != 'O' and train[f].nunique()<100 and train[f].nunique()>2) or (train[f].dtype == 'O') ]\n",
        "print(train[cat_cols].nunique())"
      ],
      "metadata": {
        "id": "8jrdwZLyoIgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nearest_val(target):\n",
        "    return min(common, key=lambda x: abs(x - target))\n",
        "\n",
        "cat_cols_updated=[]\n",
        "for col in cat_cols:\n",
        "    uncommon=list((set(test[col].unique())| set(train[col].unique()))-(set(test[col].unique())& set(train[col].unique())))\n",
        "\n",
        "    if train[col].dtype!=\"O\":\n",
        "        train[f\"{col}_cat\"]=train[col]\n",
        "        test[f\"{col}_cat\"]=test[col]\n",
        "        cat_cols_updated.append(f\"{col}_cat\")\n",
        "        if uncommon:\n",
        "            common=list(set(test[col].unique())& set(train[col].unique()))\n",
        "            train[f\"{col}_cat\"]=train[col].apply(lambda x: np.nan if x in uncommon else x)#train[col].apply(nearest_val)\n",
        "            test[f\"{col}_cat\"]=test[col].apply(lambda x: np.nan if x in uncommon else x)#test[col].apply(nearest_val)\n",
        "    else:\n",
        "        cat_cols_updated.append(col)\n",
        "        train[col]=train[col].astype(str)+\"_\"+col\n",
        "        test[col]=test[col].astype(str)+\"_\"+col\n",
        "        uncommon=list((set(test[col].unique())| set(train[col].unique()))-(set(test[col].unique())& set(train[col].unique())))\n",
        "        train[col]=train[col].apply(lambda x: np.nan if x in uncommon else x)\n",
        "        test[col]=test[col].apply(lambda x: np.nan if x in uncommon else x)\n",
        "\n",
        "print(train[cat_cols_updated].nunique())"
      ],
      "metadata": {
        "id": "l52wl091oJvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global overall_best_score\n",
        "overall_best_score = 0\n",
        "def OHE(train_df,test_df,cols,target):\n",
        "    '''\n",
        "    Function for one hot encoding, it first combines the data so that no category is missed and\n",
        "    the category with least frequency can be dropped because of redundancy\n",
        "    '''\n",
        "    combined = pd.concat([train_df, test_df], axis=0)\n",
        "    for col in cols:\n",
        "        one_hot = pd.get_dummies(combined[col]).astype(int)\n",
        "        counts = combined[col].value_counts()\n",
        "        min_count_category = counts.idxmin()\n",
        "        one_hot = one_hot.drop(min_count_category, axis=1)\n",
        "        one_hot.columns=[str(f)+col+\"_OHE\" for f in one_hot.columns]\n",
        "        combined = pd.concat([combined, one_hot], axis=\"columns\")\n",
        "        combined = combined.loc[:, ~combined.columns.duplicated()]\n",
        "\n",
        "    # split back to train and test dataframes\n",
        "    train_ohe = combined[:len(train_df)]\n",
        "    test_ohe = combined[len(train_df):]\n",
        "    test_ohe.reset_index(inplace=True,drop=True)\n",
        "    test_ohe.drop(columns=[target],inplace=True)\n",
        "    return train_ohe, test_ohe\n",
        "\n",
        "def high_freq_ohe(train, test, extra_cols, target, n_limit=50):\n",
        "    '''\n",
        "    If you wish to apply one hot encoding on a feature with so many unique values, then this can be applied,\n",
        "    where it takes a maximum of n categories and drops the rest of them treating as rare categories\n",
        "    '''\n",
        "    train_copy=train.copy()\n",
        "    test_copy=test.copy()\n",
        "    ohe_cols=[]\n",
        "    for col in extra_cols:\n",
        "        dict1=train_copy[col].value_counts().to_dict()\n",
        "        ordered=dict(sorted(dict1.items(), key=lambda x: x[1], reverse=True))\n",
        "        rare_keys=list([*ordered.keys()][n_limit:])\n",
        "#         ext_keys=[f[0] for f in ordered.items() if f[1]<50]\n",
        "        rare_key_map=dict(zip(rare_keys, np.full(len(rare_keys),9999)))\n",
        "\n",
        "        train_copy[col]=train_copy[col].replace(rare_key_map)\n",
        "        test_copy[col]=test_copy[col].replace(rare_key_map)\n",
        "    train_copy, test_copy = OHE(train_copy, test_copy, extra_cols, target)\n",
        "    drop_cols=[f for f in train_copy.columns if \"9999\" in f or train_copy[f].nunique()==1]\n",
        "    train_copy=train_copy.drop(columns=drop_cols)\n",
        "    test_copy=test_copy.drop(columns=drop_cols)\n",
        "\n",
        "    return train_copy, test_copy\n",
        "\n",
        "def cat_encoding(train, test,cat_cols_updated, target):\n",
        "    global overall_best_score\n",
        "    global overall_best_col\n",
        "    table = PrettyTable()\n",
        "    table.field_names = ['Feature', 'Encoded Features', 'Accuracy Score']\n",
        "    train_copy=train.copy()\n",
        "    test_copy=test.copy()\n",
        "    train_dum = train.copy()\n",
        "    for feature in cat_cols_updated:\n",
        "#         print(feature)\n",
        "#         cat_labels = train_dum.groupby([feature])[target].mean().sort_values().index\n",
        "#         cat_labels2 = {k: i for i, k in enumerate(cat_labels, 0)}\n",
        "#         train_copy[feature + \"_target\"] = train[feature].map(cat_labels2)\n",
        "#         test_copy[feature + \"_target\"] = test[feature].map(cat_labels2)\n",
        "\n",
        "        dic = train[feature].value_counts().to_dict()\n",
        "        train_copy[feature + \"_count\"] =train[feature].map(dic)\n",
        "        test_copy[feature + \"_count\"] = test[feature].map(dic)\n",
        "\n",
        "        dic2=train[feature].value_counts().to_dict()\n",
        "#         list1=np.arange(len(dic2.values()),0,-1) # Higher rank for high count\n",
        "        list1=np.arange(len(dic2.values())) # Higher rank for low count\n",
        "        dic3=dict(zip(list(dic2.keys()),list1))\n",
        "\n",
        "        train_copy[feature+\"_count_label\"]=train[feature].replace(dic3).astype(float)\n",
        "        test_copy[feature+\"_count_label\"]=test[feature].replace(dic3).astype(float)\n",
        "\n",
        "        temp_cols = [ feature + \"_count\", feature + \"_count_label\"]#,feature + \"_target\"\n",
        "\n",
        "        train_copy[feature]=train_copy[feature].astype(str)+\"_\"+feature\n",
        "        test_copy[feature]=test_copy[feature].astype(str)+\"_\"+feature\n",
        "\n",
        "        if train_copy[feature].nunique()<=10:\n",
        "            train_copy[feature]=train_copy[feature].astype(str)+\"_\"+feature\n",
        "            test_copy[feature]=test_copy[feature].astype(str)+\"_\"+feature\n",
        "            train_copy, test_copy = OHE(train_copy, test_copy, [feature], target)\n",
        "\n",
        "        else:\n",
        "            train_copy,test_copy=high_freq_ohe(train_copy,test_copy,[feature], target, n_limit=10)\n",
        "\n",
        "        train_copy=train_copy.drop(columns=[feature])\n",
        "        test_copy=test_copy.drop(columns=[feature])\n",
        "\n",
        "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "        ll_scores = []\n",
        "\n",
        "        for f in temp_cols:\n",
        "            X = train_copy[[f]].values\n",
        "            y = train_copy[target].values\n",
        "\n",
        "            log_loss_score = []\n",
        "            for train_idx, val_idx in kf.split(X, y):\n",
        "                X_train, y_train = X[train_idx], y[train_idx]\n",
        "                x_val, y_val = X[val_idx], y[val_idx]\n",
        "                model =  lgb.LGBMClassifier(**lgb_params)\n",
        "\n",
        "                model.fit(X_train, encode(y_train, target_map))\n",
        "                y_pred = model.predict(x_val)\n",
        "                log_loss_score.append(accuracy_score(encode(y_val, target_map),y_pred))\n",
        "\n",
        "            ll_scores.append((f, np.mean(log_loss_score)))\n",
        "            if overall_best_score < np.mean(log_loss_score):\n",
        "                overall_best_score = np.mean(log_loss_score)\n",
        "                overall_best_col = f\n",
        "        best_col, best_loss = sorted(ll_scores, key=lambda x: x[1], reverse=True)[0]\n",
        "\n",
        "        corr = train_copy[temp_cols].corr(method='pearson')\n",
        "        corr_with_best_col = corr[best_col]\n",
        "        cols_to_drop = [f for f in temp_cols if corr_with_best_col[f] > 0.5 and f != best_col]\n",
        "        final_selection = [f for f in temp_cols if f not in cols_to_drop]\n",
        "        if cols_to_drop:\n",
        "            train_copy = train_copy.drop(columns=cols_to_drop)\n",
        "            test_copy = test_copy.drop(columns=cols_to_drop)\n",
        "\n",
        "        table.add_row([feature, best_col, best_loss])\n",
        "\n",
        "    print(table)\n",
        "    print(\"overall best CV score: \", overall_best_score)\n",
        "    return train_copy, test_copy\n",
        "\n",
        "train, test= cat_encoding(train, test,cat_cols_updated, target)"
      ],
      "metadata": {
        "id": "iMWCgV6voPEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def better_features(train, test, target, cols, best_score):\n",
        "    new_cols = []\n",
        "    skf = KFold(n_splits=5, shuffle=True, random_state=42)  # Stratified k-fold object\n",
        "    best_list=[]\n",
        "    for i in tqdm(range(len(cols)), desc='Generating Columns'):\n",
        "        col1 = cols[i]\n",
        "        temp_df = pd.DataFrame()  # Temporary dataframe to store the generated columns\n",
        "        temp_df_test = pd.DataFrame()  # Temporary dataframe for test data\n",
        "\n",
        "        for j in range(i+1, len(cols)):\n",
        "            col2 = cols[j]\n",
        "            # Multiply\n",
        "            temp_df[col1 + '*' + col2] = train[col1] * train[col2]\n",
        "            temp_df_test[col1 + '*' + col2] = test[col1] * test[col2]\n",
        "\n",
        "            # Divide (col1 / col2)\n",
        "            temp_df[col1 + '/' + col2] = train[col1] / (train[col2] + 1e-5)\n",
        "            temp_df_test[col1 + '/' + col2] = test[col1] / (test[col2] + 1e-5)\n",
        "\n",
        "            # Divide (col2 / col1)\n",
        "            temp_df[col2 + '/' + col1] = train[col2] / (train[col1] + 1e-5)\n",
        "            temp_df_test[col2 + '/' + col1] = test[col2] / (test[col1] + 1e-5)\n",
        "\n",
        "            # Subtract\n",
        "            temp_df[col1 + '-' + col2] = train[col1] - train[col2]\n",
        "            temp_df_test[col1 + '-' + col2] = test[col1] - test[col2]\n",
        "\n",
        "            # Add\n",
        "            temp_df[col1 + '+' + col2] = train[col1] + train[col2]\n",
        "            temp_df_test[col1 + '+' + col2] = test[col1] + test[col2]\n",
        "\n",
        "        SCORES = []\n",
        "        for column in temp_df.columns:\n",
        "            scores = []\n",
        "            for train_index, val_index in skf.split(train, train[target]):\n",
        "                X_train, X_val = temp_df[column].iloc[train_index].values.reshape(-1, 1), temp_df[column].iloc[val_index].values.reshape(-1, 1)\n",
        "                y_train, y_val = train[target].iloc[train_index], train[target].iloc[val_index]\n",
        "                model =lgb.LGBMClassifier(**lgb_params)\n",
        "                model.fit(X_train, encode(y_train, target_map))\n",
        "                y_pred = model.predict(X_val)\n",
        "                score = accuracy_score(encode(y_val, target_map),y_pred)\n",
        "                scores.append(score)\n",
        "            mean_score = np.mean(scores)\n",
        "            SCORES.append((column, mean_score))\n",
        "\n",
        "        if SCORES:\n",
        "            best_col, best_acc = sorted(SCORES, key=lambda x: x[1],reverse=True)[0]\n",
        "            corr_with_other_cols = train.drop([target] + new_cols, axis=1).corrwith(temp_df[best_col])\n",
        "            if (corr_with_other_cols.abs().max() < 0.9 or best_acc > best_score) and corr_with_other_cols.abs().max() !=1 :\n",
        "                train[best_col] = temp_df[best_col]\n",
        "                test[best_col] = temp_df_test[best_col]\n",
        "                new_cols.append(best_col)\n",
        "                print(f\"Added column '{best_col}' with Accuracy Score: {best_acc:.4f} & Correlation {corr_with_other_cols.abs().max():.4f}\")\n",
        "\n",
        "    return train, test, new_cols\n"
      ],
      "metadata": {
        "id": "8D3Z3QCR-3gR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_features=[f for f in test.columns if train[f].nunique()>2]\n",
        "len(selected_features)\n",
        "\n",
        "# train, test,new_cols=better_features(train, test, target, selected_features, overall_best_score)\n",
        "# new_cols"
      ],
      "metadata": {
        "id": "_wBdbIYS-5wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_cols=['Curricular units 2nd sem (approved)/Marital status',\n",
        " 'Application mode+Curricular units 2nd sem (approved)_cat_count',\n",
        " 'Application order-Curricular units 2nd sem (approved)_cat_count',\n",
        " 'Course/Curricular units 2nd sem (approved)',\n",
        " 'Previous qualification+Curricular units 2nd sem (approved)_cat_count',\n",
        " 'Curricular units 2nd sem (approved)/Previous qualification (grade)',\n",
        " \"Mother's qualification-Curricular units 2nd sem (approved)_cat_count\",\n",
        " \"Father's qualification+Curricular units 2nd sem (approved)_cat_count\",\n",
        " \"Mother's occupation-Curricular units 2nd sem (approved)_cat_count\",\n",
        " \"Father's occupation+Curricular units 2nd sem (approved)_cat_count\",\n",
        " 'Admission grade*Curricular units 2nd sem (approved)',\n",
        " 'Age at enrollment-Curricular units 2nd sem (approved)_cat_count',\n",
        " 'Curricular units 1st sem (credited)+Curricular units 2nd sem (approved)_cat_count',\n",
        " 'Curricular units 1st sem (enrolled)/Curricular units 2nd sem (approved)',\n",
        " 'Curricular units 1st sem (evaluations)+Curricular units 2nd sem (approved)_cat_count',\n",
        " 'Curricular units 1st sem (approved)/Curricular units 2nd sem (approved)',\n",
        " 'Curricular units 1st sem (grade)*Curricular units 2nd sem (approved)',\n",
        " 'Curricular units 1st sem (without evaluations)-Curricular units 2nd sem (approved)_cat_count',\n",
        " 'Curricular units 2nd sem (credited)+Curricular units 2nd sem (approved)_cat_count',\n",
        " 'Curricular units 2nd sem (approved)/Curricular units 2nd sem (enrolled)',\n",
        " 'Curricular units 2nd sem (evaluations)-Curricular units 2nd sem (approved)_cat_count',\n",
        " 'Curricular units 2nd sem (approved)/Curricular units 1st sem (approved)_cat_count',\n",
        " 'Curricular units 2nd sem (grade)-Curricular units 2nd sem (approved)_cat_count',\n",
        " 'Curricular units 2nd sem (without evaluations)-Curricular units 2nd sem (approved)_cat_count',\n",
        " 'Unemployment rate-Curricular units 2nd sem (approved)_cat_count',\n",
        " 'Inflation rate-Curricular units 2nd sem (approved)_cat_count',\n",
        " 'GDP+Curricular units 2nd sem (approved)_cat_count',\n",
        " 'Marital status_cat_count*Curricular units 2nd sem (approved)_cat_count_label',\n",
        " 'Marital status_cat_count_label-Curricular units 2nd sem (approved)_cat_count',\n",
        " 'Application mode_cat_count*Curricular units 2nd sem (approved)_cat_count_label',\n",
        " 'Application mode_cat_count_label+Curricular units 2nd sem (approved)_cat_count',\n",
        " 'Application order_cat_count*Curricular units 2nd sem (approved)_cat_count_label',\n",
        " 'Application order_cat_count_label-Curricular units 2nd sem (approved)_cat_count',\n",
        " 'Course_cat_count+Curricular units 2nd sem (approved)_cat_count',\n",
        " 'Course_cat_count_label+Curricular units 2nd sem (approved)_cat_count',\n",
        " 'Previous qualification_cat_count*Curricular units 2nd sem (approved)_cat_count_label',\n",
        " 'Previous qualification_cat_count_label-Curricular units 2nd sem (approved)_cat_count',\n",
        " 'Nacionality_cat_count/Curricular units 2nd sem (approved)_cat_count',\n",
        " \"Mother's qualification_cat_count/Curricular units 2nd sem (approved)_cat_count_label\",\n",
        " \"Mother's qualification_cat_count_label-Curricular units 2nd sem (approved)_cat_count\",\n",
        " \"Father's qualification_cat_count*Curricular units 2nd sem (approved)_cat_count_label\",\n",
        " \"Father's qualification_cat_count_label-Curricular units 2nd sem (approved)_cat_count\",\n",
        " \"Mother's occupation_cat_count*Curricular units 2nd sem (approved)_cat_count_label\",\n",
        " \"Mother's occupation_cat_count_label-Curricular units 2nd sem (approved)_cat_count\",\n",
        " \"Father's occupation_cat_count*Curricular units 2nd sem (approved)_cat_count_label\",\n",
        " \"Father's occupation_cat_count_label+Curricular units 2nd sem (approved)_cat_count\",\n",
        " 'Curricular units 2nd sem (approved)_cat_count_label/Age at enrollment_cat_count',\n",
        " 'Age at enrollment_cat_count_label-Curricular units 2nd sem (approved)_cat_count',\n",
        " 'Curricular units 1st sem (credited)_cat_count+Curricular units 2nd sem (approved)_cat_count_label',\n",
        " 'Curricular units 1st sem (credited)_cat_count_label+Curricular units 2nd sem (approved)_cat_count',\n",
        " 'Curricular units 1st sem (enrolled)_cat_count+Curricular units 2nd sem (approved)_cat_count',\n",
        " 'Curricular units 1st sem (enrolled)_cat_count_label+Curricular units 2nd sem (approved)_cat_count',\n",
        " 'Curricular units 1st sem (evaluations)_cat_count*Curricular units 2nd sem (approved)_cat_count_label',\n",
        " 'Curricular units 1st sem (evaluations)_cat_count_label+Curricular units 2nd sem (approved)_cat_count',\n",
        " 'Curricular units 1st sem (approved)_cat_count-Curricular units 2nd sem (approved)_cat_count',\n",
        " 'Curricular units 1st sem (approved)_cat_count_label-Curricular units 2nd sem (approved)_cat_count',\n",
        " 'Curricular units 1st sem (without evaluations)_cat_count+Curricular units 2nd sem (approved)_cat_count_label',\n",
        " 'Curricular units 1st sem (without evaluations)_cat_count_label-Curricular units 2nd sem (approved)_cat_count',\n",
        " 'Curricular units 2nd sem (credited)_cat_count/Curricular units 2nd sem (approved)_cat_count_label',\n",
        " 'Curricular units 2nd sem (credited)_cat_count_label+Curricular units 2nd sem (approved)_cat_count',\n",
        " 'Curricular units 2nd sem (enrolled)_cat_count+Curricular units 2nd sem (approved)_cat_count',\n",
        " 'Curricular units 2nd sem (approved)_cat_count/Curricular units 2nd sem (enrolled)_cat_count_label',\n",
        " 'Curricular units 2nd sem (evaluations)_cat_count*Curricular units 2nd sem (approved)_cat_count_label',\n",
        " 'Curricular units 2nd sem (evaluations)_cat_count_label-Curricular units 2nd sem (approved)_cat_count',\n",
        " 'Curricular units 2nd sem (approved)_cat_count-Inflation rate_cat_count_label',\n",
        " 'Inflation rate_cat_count/Curricular units 2nd sem (without evaluations)_cat_count_label',\n",
        " 'Unemployment rate_cat_count_label*Inflation rate_cat_count']\n"
      ],
      "metadata": {
        "id": "x32rU1jP_AAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_arithmetic_operations(train_df, test_df, expressions_list):\n",
        "    for expression in expressions_list:\n",
        "        if expression not in train_df.columns:\n",
        "            # Split the expression based on operators (+, -, *, /)\n",
        "            parts = expression.split('+') if '+' in expression else \\\n",
        "                    expression.split('-') if '-' in expression else \\\n",
        "                    expression.split('*') if '*' in expression else \\\n",
        "                    expression.split('/')\n",
        "\n",
        "            # Get the DataFrame column names involved in the operation\n",
        "            cols = [col for col in parts]\n",
        "\n",
        "            # Perform the corresponding arithmetic operation based on the operator in the expression\n",
        "            if cols[0] in train_df.columns and cols[1] in train_df.columns:\n",
        "                if '+' in expression:\n",
        "                    train_df[expression] = train_df[cols[0]] + train_df[cols[1]]\n",
        "                    test_df[expression] = test_df[cols[0]] + test_df[cols[1]]\n",
        "                elif '-' in expression:\n",
        "                    train_df[expression] = train_df[cols[0]] - train_df[cols[1]]\n",
        "                    test_df[expression] = test_df[cols[0]] - test_df[cols[1]]\n",
        "                elif '*' in expression:\n",
        "                    train_df[expression] = train_df[cols[0]] * train_df[cols[1]]\n",
        "                    test_df[expression] = test_df[cols[0]] * test_df[cols[1]]\n",
        "                elif '/' in expression:\n",
        "                    train_df[expression] = train_df[cols[0]] / (train_df[cols[1]]+1e-5)\n",
        "                    test_df[expression] = test_df[cols[0]] /( test_df[cols[1]]+1e-5)\n",
        "\n",
        "    return train_df, test_df\n",
        "\n",
        "train, test = apply_arithmetic_operations(train, test, new_cols)\n"
      ],
      "metadata": {
        "id": "EcDAsmSF_CnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_features=[f for f in train.columns if f not in [target]]\n",
        "final_features=[*set(final_features)]\n",
        "\n",
        "sc=StandardScaler()\n",
        "\n",
        "train_scaled=train.copy()\n",
        "test_scaled=test.copy()\n",
        "train_scaled[final_features]=sc.fit_transform(train[final_features])\n",
        "test_scaled[final_features]=sc.transform(test[final_features])"
      ],
      "metadata": {
        "id": "N0QrsltqTlkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_cop, test_cop=fill_missing_numerical(train_cop, test_cop,target, max_iterations=2)\n",
        "\n",
        "missing_cols=[f for f in test_cop.columns if train_cop[f].isna().sum()+test_cop[f].isna().sum()>0]\n",
        "\n",
        "for f in missing_cols:\n",
        "    train_cop[f]=train_cop[f].fillna(train_cop[f].median())\n",
        "    test_cop[f]=test_cop[f].fillna(test_cop[f].median())"
      ],
      "metadata": {
        "id": "IxnYN0_mTl_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_cop.drop(columns=[target])\n",
        "y_train = train[target]\n",
        "\n",
        "X_test = test_cop.copy()\n",
        "\n",
        "print(X_train.shape, X_test.shape)"
      ],
      "metadata": {
        "id": "IKJqrZJXTqSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_most_important_features(X_train, y_train, n,model_input):\n",
        "    xgb_params = {\n",
        "            'n_estimators': 200,\n",
        "            'learning_rate': 0.05,\n",
        "            'max_depth': 4,\n",
        "            'subsample': 0.8,\n",
        "            'colsample_bytree': 0.1,\n",
        "            'n_jobs': -1,\n",
        "            'eval_metric': 'mlogloss',\n",
        "            'objective': 'multi:softprob',\n",
        "            'tree_method': 'hist',\n",
        "            'verbosity': 0,\n",
        "            'random_state': 42,\n",
        "        }\n",
        "    if device.lower() == 'gpu':\n",
        "            xgb_params['tree_method'] = 'gpu_hist'\n",
        "            xgb_params['predictor'] = 'gpu_predictor'\n",
        "    lgb_params = {\n",
        "            'n_estimators': 200,\n",
        "            'max_depth': 7,\n",
        "            'learning_rate': 0.05,\n",
        "            'subsample': 0.20,\n",
        "            'colsample_bytree': 0.56,\n",
        "            'reg_alpha': 0.25,\n",
        "            'reg_lambda': 5e-08,\n",
        "            'objective': 'multiclass',\n",
        "            'metric': 'multi_logloss',\n",
        "            'boosting_type': 'gbdt',\n",
        "            'random_state': 42,\n",
        "            'device': device.lower(),\n",
        "            'verbose':-1\n",
        "        }\n",
        "    cb_params = {\n",
        "            'iterations': 200,\n",
        "            'depth': 7,\n",
        "            'learning_rate': 0.1,\n",
        "            'l2_leaf_reg': 0.7,\n",
        "            'random_strength': 0.2,\n",
        "            'max_bin': 200,\n",
        "            'od_wait': 65,\n",
        "            'one_hot_max_size': 70,\n",
        "            'grow_policy': 'Depthwise',\n",
        "            'bootstrap_type': 'Bayesian',\n",
        "            'od_type': 'Iter',\n",
        "            'eval_metric': 'MultiClass',\n",
        "            'loss_function': 'MultiClass',\n",
        "            'task_type': device.upper(),\n",
        "            'random_state': 42,\n",
        "        }\n",
        "    if 'xgb' in model_input:\n",
        "        model = xgb.XGBClassifier(**xgb_params)\n",
        "    elif 'cat' in model_input:\n",
        "        model=CatBoostClassifier(**cb_params)\n",
        "    else:\n",
        "        model=lgb.LGBMClassifier(**lgb_params)\n",
        "\n",
        "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    f1_scores = []\n",
        "    feature_importances_list = []\n",
        "\n",
        "    for train_idx, val_idx in kfold.split(X_train):\n",
        "        X_train_fold, X_val_fold = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "        y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "\n",
        "        if 'lgb' in model_input:\n",
        "            model.fit(X_train_fold, encode(y_train_fold,target_map))\n",
        "        else:\n",
        "            model.fit(X_train_fold,encode(y_train_fold,target_map),verbose=False)\n",
        "\n",
        "        y_pred = model.predict(X_val_fold)\n",
        "        f1_scores.append(accuracy_score(encode(y_val_fold,target_map), y_pred))\n",
        "        feature_importances = model.feature_importances_\n",
        "        feature_importances_list.append(feature_importances)\n",
        "\n",
        "    avg_f1 = np.mean(f1_scores)\n",
        "    avg_feature_importances = np.mean(feature_importances_list, axis=0)\n",
        "\n",
        "    feature_importance_list = [(X_train.columns[i], importance) for i, importance in enumerate(avg_feature_importances)]\n",
        "    sorted_features = sorted(feature_importance_list, key=lambda x: x[1], reverse=True)\n",
        "    top_n_features = [feature[0] for feature in sorted_features[:n]]\n",
        "\n",
        "    display_features=top_n_features[:12]\n",
        "\n",
        "    sns.set_palette([(0.8, 0.5, 0.3)])\n",
        "    plt.figure(figsize=(10, 12))\n",
        "    plt.barh(range(len(display_features)), [avg_feature_importances[X_train.columns.get_loc(feature)] for feature in display_features])\n",
        "    plt.yticks(range(len(display_features)), display_features, fontsize=12)\n",
        "    plt.xlabel('Average Feature Importance', fontsize=14)\n",
        "    plt.ylabel('Features', fontsize=10)\n",
        "    plt.title(f'Top {len(display_features)} of {n} Feature Importances with best Accuracy score {avg_f1}', fontsize=16)\n",
        "    plt.gca().invert_yaxis()  # Invert y-axis to have the most important feature on top\n",
        "    plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "    plt.xticks(fontsize=8)\n",
        "    plt.yticks(fontsize=8)\n",
        "\n",
        "    # Add data labels on the bars\n",
        "    for index, value in enumerate([avg_feature_importances[X_train.columns.get_loc(feature)] for feature in display_features]):\n",
        "        plt.text(value + 0.005, index, f'{value:.3f}', fontsize=12, va='center')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return top_n_features"
      ],
      "metadata": {
        "id": "D1juTLB6Tt1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_imp_features_cat=get_most_important_features(X_train.reset_index(drop=True), y_train,150, 'cat')\n",
        "n_imp_features_xgb=get_most_important_features(X_train.reset_index(drop=True), y_train,150, 'xgb')\n",
        "n_imp_features_lgbm=get_most_important_features(X_train.reset_index(drop=True), y_train,150, 'lgbm')"
      ],
      "metadata": {
        "id": "4CmV2CMFTv2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_imp_features=[*set(n_imp_features_xgb+n_imp_features_lgbm+n_imp_features_cat)]\n",
        "print(f\"{len(n_imp_features)} features have been selected from three algorithms for the final model\")\n",
        "\n",
        "X_train=X_train[n_imp_features]\n",
        "X_test=X_test[n_imp_features]"
      ],
      "metadata": {
        "id": "G5yxyG0sTxyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = np.unique(y_train)  # Get unique class labels\n",
        "class_to_index = {cls: idx for idx, cls in enumerate(classes)}\n",
        "y_train_numeric = np.array([class_to_index[cls] for cls in y_train])\n",
        "\n",
        "class_counts = np.bincount(y_train_numeric)\n",
        "\n",
        "total_samples = len(y_train_numeric)\n",
        "\n",
        "class_weights = total_samples / (len(classes) * class_counts)\n",
        "\n",
        "class_weights_dict = {target_map[cls]: weight for cls, weight in zip(classes, class_weights)}\n",
        "\n",
        "print(\"Class counts:\", class_counts)\n",
        "print(\"Total samples:\", total_samples)\n",
        "print(\"Class weights:\", class_weights)\n",
        "print(\"Class weights dictionary:\", class_weights_dict)"
      ],
      "metadata": {
        "id": "c2pP0PzlT0on"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}