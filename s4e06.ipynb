{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 1"
      ],
      "metadata": {
        "id": "SFz-9ZwILbl0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NoRiqXz05JKd"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "import numpy as np\n",
        "import os\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import missingno as msno\n",
        "from prettytable import PrettyTable\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "sns.set(style='darkgrid', font_scale=1.4)\n",
        "from tqdm import tqdm\n",
        "from tqdm.notebook import tqdm as tqdm_notebook\n",
        "tqdm_notebook.get_lock().locks = []\n",
        "# !pip install sweetviz\n",
        "# import sweetviz as sv\n",
        "import concurrent.futures\n",
        "from copy import deepcopy\n",
        "from functools import partial\n",
        "from itertools import combinations\n",
        "import random\n",
        "from random import randint, uniform\n",
        "import gc\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler,PowerTransformer, FunctionTransformer\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from itertools import combinations\n",
        "from sklearn.impute import SimpleImputer\n",
        "import xgboost as xg\n",
        "from sklearn.model_selection import train_test_split,cross_val_score\n",
        "from sklearn.metrics import mean_squared_error,mean_squared_log_error, roc_auc_score, accuracy_score, f1_score, precision_recall_curve, log_loss\n",
        "from sklearn.cluster import KMeans\n",
        "!pip install yellowbrick\n",
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "!pip install gap-stat\n",
        "from gap_statistic.optimalK import OptimalK\n",
        "from scipy import stats\n",
        "import statsmodels.api as sm\n",
        "from scipy.stats import ttest_ind\n",
        "from scipy.stats import boxcox\n",
        "import math\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "!pip install optuna\n",
        "import optuna\n",
        "!pip install cmaes\n",
        "import cmaes\n",
        "import xgboost as xgb\n",
        "!pip install catboost\n",
        "!pip install lightgbm --install-option=--gpu --install-option=\"--boost-root=C:/local/boost_1_69_0\" --install-option=\"--boost-librarydir=C:/local/boost_1_69_0/lib64-msvc-14.1\"\n",
        "import lightgbm as lgb\n",
        "!pip install category_encoders\n",
        "from category_encoders import OneHotEncoder, OrdinalEncoder, CountEncoder, CatBoostEncoder\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier, GradientBoostingClassifier,ExtraTreesClassifier, AdaBoostClassifier, HistGradientBoostingRegressor\n",
        "!pip install -U imbalanced-learn\n",
        "from imblearn.ensemble import BalancedRandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from catboost import CatBoost, CatBoostRegressor, CatBoostClassifier\n",
        "from sklearn.svm import NuSVC, SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifierCV, LogisticRegressionCV\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from catboost import Pool\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "pd.pandas.set_option('display.max_columns',None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "table = PrettyTable()\n",
        "\n",
        "table.field_names = ['Feature', 'Data Type', 'Train Missing %', 'Test Missing %',\"Original Missing%\"]\n",
        "for column in train_copy.columns:\n",
        "    data_type = str(train_copy[column].dtype)\n",
        "    non_null_count_train= np.round(100-train_copy[column].count()/train_copy.shape[0]*100,1)\n",
        "    if column!=target:\n",
        "        non_null_count_test = np.round(100-test_copy[column].count()/test_copy.shape[0]*100,1)\n",
        "    else:\n",
        "        non_null_count_test=\"NA\"\n",
        "    non_null_count_orig= np.round(100-original_copy[column].count()/original_copy.shape[0]*100,1)\n",
        "    table.add_row([column, data_type, non_null_count_train,non_null_count_test,non_null_count_orig])\n",
        "print(table)"
      ],
      "metadata": {
        "id": "8aIQMMcDLmen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_pie_chart(data, title, ax):\n",
        "    data_counts = data[target].value_counts()\n",
        "    labels = data_counts.index\n",
        "    sizes = data_counts.values\n",
        "    colors = [ (0.2, 0.9, 0.6), 'crimson', (0.8, 0.5, 0.3)]\n",
        "    explode = (0.1,0.05, 0)\n",
        "\n",
        "    ax.pie(sizes,explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=140)\n",
        "    ax.axis('equal')\n",
        "    ax.set_title(title)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(18, 6))  # Create three subplots in a row\n",
        "\n",
        "plot_pie_chart(train_copy, \"Train Churn Distribution\", axes[0])\n",
        "plot_pie_chart(original, \"Original Churn Distribution\", axes[1])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UYwEYXy-dLRB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}